# Fast Data Switch Adaptor

## 简述

Fast Data Switch Adaptor是一个异构的数据交换工具，致力于使用一个工具解决不同数据源（JDBC、FILE、Kafka、FTP等）之间数据交换的问题。

Fast Data Switch Adaptor在设计上采用“框架+插件”的结构，具有较好的扩展性。框架相当于数据缓冲区，实现单机模式（基于disruptor），分布式（基于消息机制），插件则为访问不同的数据源和处理提供实现。



## 特性


1. 极简的使用体验
   绿色版本，跨平台部署运行，WebUI操作
3. 异构数据源之间交换
4. 丰富的数据转换功能
   基于插件模式，易扩展，除了提供数据快照搬迁功能之外，还提供了丰富数据转换的功能，让数据在传输过程中可以轻松完成数据脱敏，补全，过滤等数据转换功能，另外还提供了自动groovy函数，让用户自定义转换函数。
5. 可靠的数据质量监控
提供作业全链路的流量、数据量运行时监控，将作业本身状态、数据流量、数据速度、执行进度等信息进行全面的展示，让用户可以实时了解作业状态。并可在作业执行过程中智能判断源端和目的端的速度对比情况，给予用户更多性能排查信息。
6. 提供脏数据探测
在数据的传输过程中，必定会由于各种原因导致很多数据传输报错(比如类型转换错误)，提供脏数据收集让用户准确把控数据质量大关！

精准的速度控制
提供了包括通道(并发)、记录流、字节流三种流控模式，可以随意控制你的作业速度，让你的作业在库可以承受的范围内达到最佳的同步速度

健壮的容错机制

  
## 设计

1. 配置文件：使用json格式配置DataSource、DataPipeLine、DataTarget的参数。
2. 插件模式：数据读取、处理和数据写入均基于插件实现。
3. 事件监听模式: 数据的交换使用高性能环形数据缓冲区实现调整、异步的数据交换。
4. 在分布式时Master负责高度与状态监控，各子节点负责数据读取，处理与写入。

# Data Source、Process、Target

## config 配置数据源

## scheme 获取元数据

## sinkTo下沉到数据处理或数据目标



# Data Pipeline

## disruptor 单机模式

## distributor 分布式模式